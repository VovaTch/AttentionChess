{
    "name": "AttentionChess",
    "n_gpu": 1,

    "arch": {
        "type": "AttChess",
        "args": {
            "num_heads": 4,
            "num_encoder": 4,
            "num_decoder": 4,
            "num_chess_conv_layers": 0,
            "p_embedding": true,
            "dropout": 0.0,
            "ripple_net": true
        }
    },
    "data_loader": {
        "type": "RuleAttentionChessLoader",
        "args":{
            "batch_size": 16,
            "shuffle": true,
            "validation_split": 0.0,
            "num_workers": 1
        }
    },
    "optimizer": {
        "type": "AdamW",
        "args":{
            "lr": 1e-2,
            "weight_decay": 1e-6,
            "amsgrad": false
        }
    },
    "loss":
    {
        "type": "Criterion",
        "args": {
            "eos_coef": 1,
            "losses": ["quality_loss", "board_value_loss"]
        }
    },
    "loss_weights":
    {
        "loss_quality": 1,
        "loss_board_value": 1
    },
    "metrics": [
        "quality_loss", "board_value_loss"
    ],
    "lr_scheduler": {
        "type": "OneCycleLR",
        "args": {
            "max_lr": 1e-2,
            "div_factor": 1000,
            "total_steps": 128000,
            "three_phase": false
        }
    },
    "trainer": {
        "epochs": 5000,

        "save_dir": "saved/",
        "save_period": 1,
        "verbosity": 2,
        
        "monitor": "min val_loss",
        "early_stop": 1e10,
        "clip_grad_norm": 0.1,

        "tensorboard": true
    }
}
